<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>

<HEAD>
	<META HTTP-EQUIV="Content-Type" CONTENT="text/html;CHARSET=iso-8859-1">
<META NAME="VPSiteProject" CONTENT="file:///C|/cvs/Triceps/TricepsHTML.vpp">

	<META NAME="GENERATOR" Content="Visual Page 2.0 for Windows">
	<TITLE>GAF&amp;BPRS Study</TITLE>
</HEAD>

<BODY>

<P ALIGN="CENTER"><B><FONT SIZE="4">Clinical Research Proposal</FONT></B></P>
<P ALIGN="CENTER">Thomas M. White, MD, MS<BR>
Department of Medical Informatics<BR>
Columbia Presbyterian Medical Center<BR>
New York State Psychiatric Institute<BR>
<A HREF="mailto:tw176@columbia.edu">tw176@columbia.edu</A><B><BR>
</B>July 13, 2000</P>
<P ALIGN="CENTER"><B><BR>
Working Title</B></P>
<P>Using Informatics to Improve the Reliability and Validity of Established Assessment Instruments: GAF and BPRS
as Examples</P>
<P ALIGN="CENTER"><B>Introduction</B></P>
<P>Psychometric instruments are commonly used to assess the status of patients, and to evaluate the efficacy of
new drugs. Two of the most commonly used instruments are the Global Assessment of Functioning (GAF)(<A HREF="#1">1</A>),
which is a required component of psychiatric diagnoses, and the Brief Psychiatric Rating Scale (BPRS)(<A HREF="#2">2</A>)
which is commonly used to assess schizophrenic patients. Over the decades, many renditions of each of these instruments
have been created and utilized. However, there is ongoing debate as to which of them is the best, and whether there
might be other instruments that are more sensitive or specific to different patient populations. Some of the concerns
include: (a) many rating scales omit core symptoms or do not reflect the current understanding of the phenomenology
of disorders they attempt to assess(<A HREF="#3">3</A>), (b) most rating scales combine assessments of multiple
symptoms into a single result, so medications that improve some symptoms but worsen others (e.g. side effects)
may appear to have no effect if the rating scale is the only measure of their efficacy, and (c) recent factor analysis
studies of the BPRS(<A HREF="#4">4</A>,<A HREF="#5">5</A>) have identified new factor clusters that are more sensitive
measures of outcomes than those subscales identified by factor analytic studies performed in the mid-70s(<A HREF="#6">6</A>,<A
HREF="#7">7</A>). These studies suggest that other instruments would also benefit from re-analysis to assess their
efficacy as predictors of measures of outcomes. Unfortunately, the barriers to creating and validating new or revised
psychometric instruments has been daunting.</P>

<P>Clearly, clinical care and psychopharmacological studies would both benefit from psychometric instruments with
demonstrated improvements in speed, reliability, and ease of use and analysis. Moreover, as federal research requirements
increasinginly focus on assuring the privacy and security of medical information, HIPAA compliant data collection
and analysis tools may soon become a necessary research requirement.</P>

<P><I>Triceps</I> is a novel language and application designed by the author to lower the barrier to implementing
and assessing psychometric instruments. Using Triceps, it will be possible to implement and compare web-browser
based versions of the several commonly used renditions of the GAF and BPRS. It will also be possible to assess
the standard psychometric properties of these revised instruments.</P>

<P>This study will consist of two phases.  Phase one will compare several variants of the GAF and BPRS to the gold
standard, assessing their construct validity, inter-rater reliability, and usability.  The best variants of the
GAF and BPRS will be used for Phase two, which assess in more detail potential cross-discipline inter-rater reliability
differences between the selected computerized versions and the original instruments.</P>

<P>The hope and goal of this study is to demonstrate a methodology for assessing and improving the operational
quality and usability of valuable assessment instruments, and to make these revised instruments available for research
and/or clinical use. This field-validation of Triceps [which will soon be HIPAA compliant] will show how it can
lower the barrier to devising and/or assessing other psychometric and outcomes instruments, and serve as a valuable
clincal and research tool.

<UL>
	<UL>
		<P>
	</UL>
</UL>

<P ALIGN="CENTER"><B>Methods</B></P>
<P><B>Instruments</B></P>

<UL>
	<LI>GAF (DSM-IV)
	<UL>
		<LI>single page of instructions; two digit answer
	</UL>
	<LI>GAFTree (<A HREF="#8">8</A>) (M. First)
	<UL>
		<LI>decision tree designed to yield appropriate GAF score in shortest number of steps and amount of time
	</UL>
	<LI>e-GAF (T White)
	<UL>
		<LI>subdivides GAF into 15 sub-scales, collecting results for each, and calculating GAF from them
	</UL>
	<LI>BPRS - paragraph form
	<UL>
		<LI>18 questions, with verbose description for each
	</UL>
	<LI>e-BPRS (T White)
	<UL>
		<LI>18 questions, with instructions organized by inclusion &amp; exclusion criteria, as well as terse examples
		for each answer option
	</UL>
	<LI>Usability Survey (adapted from <A HREF="#9">9</A>)
	<UL>
		<LI>~15 questions to assess the satisfaction with and ease of use Triceps as a web-based assessment instrument
	</UL>
</UL>

<P><B>Assessment Scenarios</B></P>

<UL>
	<LI>26 Case Vignettes designed for GAF (M First et al.?) with gold-standard assessments of the appropriate GAF
	score for each (ref?)
	<LI>[can these also be used for the BPRS? If so, how should a &quot;gold-standard&quot; score be generated?]
</UL>

<P><B>Subjects</B></P>

<UL>
	<LI>[Restricted to individuals who have email addresses since deployed via the web]
	<LI>2nd year medical students who have taken Intro Psychiatry (e.g. Columbia &amp; Cornell - about 200 if all respond)
	<LI>Psychiatry vs. non-Psychiatry residents (how many available?)
	<LI>Psychiatry vs. non-Psychiatry attendings (how many available?)
	<LI>Psychiatric vs. non-Psychiatric nurses (how many available?)
	<LI>Psychiatric vs. non-Psychiatric social workers (how many available?)
</UL>

<P><B>Questions</B></P>

<BLOCKQUOTE>
	<P><B>Phase 1:</B></P>

	<P>Validate the computerized versions of the GAF and BPRS. Select the electronic versions with the highest inter-rater
	reliability for Step 2.</P>
</BLOCKQUOTE>


<UL>
	<UL>
		<LI>Construct Validity / Intrument Equivalence
		<UL>
			<LI>Are the e-GAF and e-BPRS construct valid as compared to the traditional GAF and BPRS, using the GAF vignette
			scores as a gold standard? (e.g. t-Test: do they deviate around the same mean?)
		</UL>
		<LI>Inter-Rater Reliability
		<UL>
			<LI>Is there a significant difference in the amount of variance of responses and/or amount of time required to
			complete the GAF <I>vs</I>. GAFTree <I>vs</I>. e-GAF? (e.g. F-test)
			<LI>Is there a significant difference in the amount of variance of responses and/or amount of time required to
			complete the BPRS <I>vs.</I> BPRS-paragrph <I>vs</I>. e-BPRS? (e.g. F-test)
			<LI>Which subscales of the e-GAF and e-BPRS have the lowest content validity? (e.g. the highest variance?)
		</UL>
		<LI>Usability
		<UL>
			<LI>Which of the GAF and BPRS variants are preferred? (e.g. frequency analysis)
		</UL>
	</UL>
</UL>


<BLOCKQUOTE>
	<P><B>Phase 2:</B></P>

	<P>Assess whether standardized, computerized versions of the GAF and BPRS might represent a significant and meaningful
	improvement over the traditional BPRS and GAF. In order to eliminate the obvious effect of computerized <I>vs.</I>
	paper versions, all versions will be implemented and deployed using the same computer system. This way, they will
	share the same look-and-feel and training/learning effects. The only difference among the computerized instruments
	will be wording and visibility of the instructions, questions and help (thus the cognitive load on the user), and
	the sequence/flow of the questions.</P>
</BLOCKQUOTE>


<UL>
	<UL>
		<LI>Inter-Rater Reliability across Disciplines
		<UL>
			<LI>Are there significant differences across profession in the inter-rater reliabilities of subjects on the optimized
			<I>vs.</I> traditional GAF and BPRS? (e.g. ANOVA of (score minus gold-standard) with profession and instrument#
			as independent variables)
			<LI>Are there significant differences across profession in the time required to complete the optimized <I>vs.</I>
			traditional GAF and BPRS? (e.g. ANOVA of time-to-complete with profession and instrument# as independent variables)
			<LI>What is the relationship between time-to-complete and accuracy when viewed across profession? (e.g. ROC curve(?)
			of accuracy vs. time)
			<LI>Which subscales of the optimized GAF and BPRS have the lowest content validity? (e.g. the highest variance?)
			(factor analysis?)
		</UL>
		<LI>Training Effects
		<UL>
			<LI>the same four questions as above, but either adding case# or time as in independent variable <I>or</I> a new
			study sample focusing on a paticular profession of interest.
		</UL>
	</UL>
</UL>

<P><B>Time Requirement per Subject</B></P>

<UL>
	<LI>estimated at 2-5 minutes per case, depending upon the subject's prior familiarity with the instruments and
	instructions.
</UL>

<P><B>Deployment</B></P>

<UL>
	<LI>Triceps will be used to author and administer each of these instruments
	<LI>Each subject will be emailed an invitation to participate
	<UL>
		<LI>there will be a brief description of the goals of study (if appropriate), the estimated time-commitment required,
		and the person to contact in case of questions or concerns
		<LI>a message such as
		<UL>
			<LI>Hi, I am a graduate of Cornell Med School doing a clinical and informatics research fellow at CPMC and PI.
			I am conducting a study to assess which of several computerized versions of the GAF and BPRS are most sensitive,
			reliable, and efficient in the clinical environment. Your department has identified you as a [psychiatric/non-psychiatric]
			[medical student/resident/attending/nurse/sw] at [NYH/CPMC/PI]. As such, you are invited to participate in this
			email-based study, which should take less than 5 minutes of your time.
			<LI>The study is composed of 26 one-paragraph case vignettes of fictitious patients. You will be asked to determine
			the GAF and BPRS scores for each &quot;patient&quot;. It should take you from 1-5 minutes to read and assess each
			case, depending upon your level of experience.
			<LI>You are not required to complete all 26 cases.
			<LI>However, these vignettes are educationally useful. After you have scored each case, you will be shown the GAF
			and BPRS scores the experts agree is most correct, and provided with a detailed description of the reasons behind
			their decisions.
			<LI>Thus, you may want to complete several or all of the cases, at your leisure.
			<LI>You can return to complete, or re-do each case as many times as you like.
			<LI>Your privacy is paramount. You may notice that the link to the study's home page contains an unique alphanumeric
			key. Although your email addresses were collected from the departmental lists, neither I nor the automated analysis
			system keeps track of your name (or email address) after the access key has been sent to you. The key only contains
			references to you profession, level of training, and institution. [So trainees, you don't have to worry about your
			supervisor getting hold of your individual results].
			<LI>Thank you for your participation. If you have any questions or comments, please don't hesitate to contact me
			at <A HREF="mailto:tw176@columbia.edu">tw176@columbia.edu</A>.
			<LI>----- Thomas M. White, MD, MS; Clinical Research Fellow, Department of Medical Informatics, CPMC/NYSPI ----
		</UL>
		<LI>a link will point them to the entry page for the study. Embedded within it will be a key with which to uniquely
		but anonymously identify them to the system
	</UL>
	<LI>Entry page
	<UL>
		<LI>instructions &amp; time-to-complete
		<LI>who to contact in case of questions or concerns
		<LI>a button to decline to participate
		<LI>buttons to start each of the 26 studies (one per vignette)
	</UL>
	<LI>The System (Triceps) will, for each case:
	<UL>
		<LI>authenticate each subject, ensuring that non-authorized individuals are not able to contaminate the study data
		<LI>record the subjectID, profession, training level, and institution for each subject
		<LI>record copious timing information for each case
		<UL>
			<LI>date/time that subject first sees the case vignette
			<LI>date/time that subjects starts the assessment of case
			<LI>every event (key press, mouse click, help-request, submit) at every stage within the assessment - to millisecond
			accuracy
		</UL>
		<LI>calculate and store the GAF and BPRS scores based upon the subject's inputs
		<LI>upon completion of a case, report back to the subject the expert consensus as to what the GAF and BPRS score
		should be, and an explanation as to why
		<LI>email a message to the subject thanking them for participating in the study, and inviting them to fill out
		a 15 question survey evaluating the Triceps system itself (independent of the GAF and BPRS content).
	</UL>
</UL>

<P ALIGN="CENTER"><B>Analysis</B></P>

<UL>
	<LI>As indicated above in the <I>Questions</I> section.
	<LI>Alternatively, if it is possible to collect a sufficient N:
	<UL>
		<LI>MANCOVA of accuracy vs. time-to-complete of GAF and BPRS (total scores &amp; subscales) with computerized-version#,
		profession, educational level, institute(?), case#, sequence# [the order in which the subject completed the vignette],
		and date/time(?) as independent variables.
		<LI>Reliability of GAF/BPRS sub-components / sub-scales (e.g. which sub-components contribute the most variance
		to the GAF/BPRS scores).
	</UL>
	<LI>Triceps satisfaction survey.
	<LI>Assessment of respondents vs. non-respondents.
</UL>

<P ALIGN="CENTER"><B>Required Resources</B>

<UL>
	<LI>A clinical research advisor who will:
	<UL>
		<LI>help facilitate the establishment and maintenance of liaisons with the medical schools
		<LI>provide critical review of the design and analysis of this study
		<LI>suggest potential ways to enhance or extend this study
		<LI>suggest best granting agencies and journals to target with the results of this study
		<LI>help guide me through the grant application and publication processes
		<LI>provide critical review of manuscripts
		<LI>suggest appropriate conferences at which preliminary results should be presented.
	</UL>
	<LI>Liaisons to NYH and CPMC medical schools for permission (and hopefully blessing) to conduct this study, as
	well as to access the necessary email lists.
	<LI>Permission to use the GAF vignettes.
	<LI>IRB permission to collect numerical assessment of fictitious &quot;patients&quot; from anonymized health care
	workers?
	<LI>Access to or collaboration with a statistician who will:
	<UL>
		<LI>help guide me through the planning and implementation of this study (e.g. power analyses, fall-back options
		if # respondants are too small, etc.)
		<LI>suggest improvements and/or extensions to the design and analysis of this data
	</UL>
	<LI>Access to appropriate statistical analysis and graphical reporting software.
	<LI>Access to secure, frequently backed-up storage space for the &quot;database&quot; of subjects and their results.
	<LI>Technical
	<UL>
		<LI>author and get assessments of the Triceps implementations of the GAF, GAF-Tree, e-GAF, BPRS-paragraph, and
		e-BPRS
		<LI>author intro-page for the study
		<LI>minor revisions to Triceps to support subject authentication, and transfer of completed data to secure storage
		space
		<LI>(?) less minor, and less crucial revisions to Triceps to support direct linkage to database, such as mySQL
		<LI>(?) less crucial - implement HIPPA compliance
		<UL>
			<LI>secure storage
			<LI>authentication, access restrictions, and logging of access to data
		</UL>
	</UL>
</UL>

<P ALIGN="CENTER"><B>Funding</B></P>
<P>To be determined ...</P>
<P ALIGN="CENTER"><B>References</B></P>

<OL>
	<LI><A NAME="1"></A>Endicott J, Spitzer RL, Fleiss JL, et al: The Global Assessment Scale: a procedure for measuring
	overall severity of psychiatric disturbance. Arch Gen Psychiatry 33:766–771,1976<B>.</B>
	<LI><A NAME="2"></A>Overall JE, Gorham DR. The Brief Psychiatric Rating Scale. Psychol Rep 1962;10:799-812.
	<LI><A NAME="3"></A>Laska EM, Klein DF, Lavori PW et al. Design issues for the clinical evaluation of psychotropic
	drugs. In: Prien RF, Robinson DS, eds. Clinical Evaluation of Psychotropic Drugs: Principles and Guidelines. New
	York: Raven Press, 1994;29-67.
	<LI><A NAME="4"></A>Harvey PD, Davidson M, White L, et al. Empirical evaluation of the factorial structure of clinical
	symptoms in schizophrenia: effects of typical neuroleptics on the Brief Psychiatric Rating Scale. Biological Psychiatry
	1996;40:755-760.
	<LI><A NAME="5"></A>Mueser KT, Curran PJ, McHugo GJ. The factor structure of the Brief Psychiatric Rating Scale
	in schizophrenia. Psychological Assessment 1997, in press.
	<LI><A NAME="6"></A>Guy W, Cleary P, Bonato RR. Methodological implications of a large central data system. Proceedings
	IXth Congress CINP. Amsterdam: Excerpta Medica, 1975.
	<LI><A NAME="7"></A>Overall JE. The Brief Psychiatric Rating Scale in psychopharmacologic research. Mod Probl Pharmacopsychiatry
	1974;7:67-78.
	<LI><A NAME="8"></A>***GAF-Tree reference***
	<LI><A NAME="9"></A>Schneiderman B. Designing the User Interface: Strategies for effective human computer interaction,
	3rd Ed.. Massachusetts: Addison-Wesley, 1998; 135-144.
</OL>


</BODY>

</HTML>
