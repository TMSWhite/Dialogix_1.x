<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>

<HEAD>
	<META HTTP-EQUIV="Content-Type" CONTENT="text/html;CHARSET=iso-8859-1">
<META NAME="VPSiteProject" CONTENT="file:///C|/cvs/Triceps/TricepsHTML.vpp">

	<TITLE>GAF&amp;BPRS Study</TITLE>
</HEAD>

<BODY>

<P ALIGN="CENTER"><B>Working Title</B></P>
<P>The Future of Psychiatric Research: Challenges, Solutions, Opportunities, and Mandates</P>
<P>The Foundation of Evidence-Based Medicine - our Standardized Assessment Instruments - Has Crumbled. Rebuilding
the Temple in the Modern Age.</P>
<P ALIGN="CENTER"><B>Abstract</B></P>
<P>As clinicians, we use evidence-based medicine to ensure the highest quality clinical care for our patients.
Thus, we seek information about new treatment regimens that will help our patient populations. Much of this research
is in the form <I>treatment Rx helps patients with disease Dx as seen by improvements in their symptoms (Sx) as
measured by the standardized instrument I</I>. Moreover, our assessment of which psychiatric disease Dx a patient
has is dependent upon the diagnostic criteria, which were derived from research using other standardized instruments.<B>
</B>Thus, our ability to provide quality care - to accurately assess, diagnose, treat, monitor, and manage our
patients - is dependent upon the quality of these standardized instruments.</P>

<P><BR>
Many people hope to use the Internet as a forum in which they can express their opinions via on-line polls, explore
their interests via on-line education and testing, and seek medical advice tailored to their individual circumstances.
Many businesses are striving to provide these services, but are often hindered by economic, technological, political,
and sociological challenges. These hurdles have also made if difficult for researchers to identify and evaluate
new and better ways to provide these services. The goal of the Triceps project was to help researchers lower these
hurdles and speed the development of improved services.</P>

<P>Communication barriers contribute to many of these hurdles, which is not surprising given how many different
groups and disciplines are necessary to design, build, test, and market improved services. The informatics fields
of knowledge acquisition, representation, and transfer address the challenge of getting and expert to codify their
knowledge in a fashion that a programmer can implement.</P>

<P></P>
<P ALIGN="CENTER"><B>Introduction</B></P>
<P>Standardized assessment instruments measuring symptoms, socio-occupational functioning, and quality of life
are commonly used when diagnosing patients, evaluating the efficacy of new drugs and treatments, tracking clinical
outcomes, and conducting epidemiologal research.  Thus, the quality of this research, and much of evidence-based
medicine in general, is intimately tied to the quality of these assessment instruments.  Over the decades, researchers
have developed and psychometrically assessed a myriad of competing instruments, and those with the best reliability
and validity were chosen as standards for most clinical trails.  The quality of the chosen standards is hotly debated
since many instruments (a) omit core symptoms or do not reflect the current understanding of the phenomenology
and demographics of the disorders they attempt to assess, (b) inappropriately combine multiple nominal measurements
into artificially ordinal scales, and (c) are inappropriately used to assess populations for which they were not
designed.  Moreover, variants of the standards are often used instead of the originals.  The changes in wording,
user interface, and training-needs can have dramatic effects upon the inter-rater and repeat reliability of these
instruments, and thus the validity of the data.  Clearly, clinical care and trials would benefit from new or revised
instruments, as well as improvements in the speed with which they can be developed, validated, and deployed; and
the ease with which the collected data can be analyzed.  Unfortunately, the barriers to addressing these issues
has been daunting.</P>

<P>This talk will discuss <I>Triceps</I>, an infrastructure designed to facilitate this process.  The talk will
discuss the informational, political, technological, and statistical challenges that hinder this process, as well
as the theory behind and architecture of the Triceps approach to addressing these problems.  </P>

<UL>
	<UL>
		<P>
	</UL>
</UL>

<P ALIGN="CENTER"><B>Methods</B></P>
<P><B>Instruments</B></P>

<UL>
	<LI>GAF (DSM-IV)
	<UL>
		<LI>single page of instructions; two digit answer
	</UL>
	<LI>GAFTree (<A HREF="#8">8</A>) (M. First)
	<UL>
		<LI>decision tree designed to yield appropriate GAF score in shortest number of steps and amount of time
	</UL>
	<LI>e-GAF (T White)
	<UL>
		<LI>subdivides GAF into 15 sub-scales, collecting results for each, and calculating GAF from them
	</UL>
	<LI>BPRS - paragraph form
	<UL>
		<LI>18 questions, with verbose description for each
	</UL>
	<LI>e-BPRS (T White)
	<UL>
		<LI>18 questions, with instructions organized by inclusion &amp; exclusion criteria, as well as terse examples
		for each answer option
	</UL>
	<LI>Clinical Utility Survey (T White)
	<UL>
		<LI>10 questions to assess whether the subjects might use such computerized instruments; and solicitation of opinions
		on how these particular implementations might be improved.
	</UL>
	<LI>Overall Usability Survey (adapted from <A HREF="#9">9</A>)
	<UL>
		<LI>15 questions to assess the satisfaction with and ease of use Triceps as a web-based assessment instrument
	</UL>
</UL>

<P><B>Assessment Scenarios</B></P>

<UL>
	<LI>26 Case Vignettes designed for GAF (M First et al.?) with gold-standard assessments of the appropriate GAF
	score for each (ref?)
	<LI>[can these also be used for the BPRS? If so, how should a &quot;gold-standard&quot; score be generated?]
</UL>

<P><B>Subjects</B></P>

<UL>
	<LI>[Restricted to individuals who have email addresses since deployed via the web]
	<LI>2nd year medical students who have taken Intro Psychiatry (e.g. Columbia &amp; Cornell - about 200 if all respond)
	<LI>Psychiatry vs. non-Psychiatry residents (how many available?)
	<LI>Psychiatry vs. non-Psychiatry attendings (how many available?)
	<LI>Psychiatric vs. non-Psychiatric nurses (how many available?)
	<LI>Psychiatric vs. non-Psychiatric social workers (how many available?)
</UL>

<P><B>Questions</B></P>

<BLOCKQUOTE>
	<P><B>Phase 1:</B></P>
	<P>Validate the computerized versions of the GAF and BPRS. Select the electronic versions with the highest inter-rater
	reliability for Step 2.</P>
</BLOCKQUOTE>


<UL>
	<UL>
		<LI>Construct Validity / Intrument Equivalence
		<UL>
			<LI>Are the e-GAF and e-BPRS construct valid as compared to the traditional GAF and BPRS, using the GAF vignette
			scores as a gold standard? (e.g. t-Test: do they deviate around the same mean?)
		</UL>
		<LI>Inter-Rater Reliability
		<UL>
			<LI>Is there a significant difference in the amount of variance of responses and/or amount of time required to
			complete the GAF <I>vs</I>. GAFTree <I>vs</I>. e-GAF? (e.g. F-test)
			<LI>Is there a significant difference in the amount of variance of responses and/or amount of time required to
			complete the BPRS <I>vs.</I> BPRS-paragrph <I>vs</I>. e-BPRS? (e.g. F-test)
			<LI>Which subscales of the e-GAF and e-BPRS have the lowest content validity? (e.g. the highest variance?)
		</UL>
		<LI>Usability
		<UL>
			<LI>Which of the GAF and BPRS variants are preferred? (e.g. frequency analysis)
		</UL>
	</UL>
</UL>


<BLOCKQUOTE>
	<P><B>Phase 2:</B></P>
	<P>Assess whether standardized, computerized versions of the GAF and BPRS might represent a significant and meaningful
	improvement over the traditional BPRS and GAF. In order to eliminate the obvious effect of computerized <I>vs.</I>
	paper versions, all versions will be implemented and deployed using the same computer system. This way, they will
	share the same look-and-feel and training/learning effects. The only difference among the computerized instruments
	will be wording and visibility of the instructions, questions and help (thus the cognitive load on the user), and
	the sequence/flow of the questions.</P>
</BLOCKQUOTE>


<UL>
	<UL>
		<LI>Inter-Rater Reliability across Disciplines
		<UL>
			<LI>Are there significant differences across profession in the inter-rater reliabilities of subjects on the optimized
			<I>vs.</I> traditional GAF and BPRS? (e.g. ANOVA of (score minus gold-standard) with profession and instrument#
			as independent variables)
			<LI>Are there significant differences across profession in the time required to complete the optimized <I>vs.</I>
			traditional GAF and BPRS? (e.g. ANOVA of time-to-complete with profession and instrument# as independent variables)
			<LI>What is the relationship between time-to-complete and accuracy when viewed across profession? (e.g. ROC curve(?)
			of accuracy vs. time)
			<LI>Which subscales of the optimized GAF and BPRS have the lowest content validity? (e.g. the highest variance?)
			(factor analysis?)
		</UL>
		<LI>Training Effects
		<UL>
			<LI>the same four questions as above, but either adding case# or time as in independent variable <I>or</I> a new
			study sample focusing on a paticular profession of interest.
		</UL>
	</UL>
</UL>

<P><B>Time Requirement per Subject</B></P>

<UL>
	<LI>estimated at 5 minutes per case, depending upon the subject's prior familiarity with the instruments and instructions.
</UL>

<P><B>Deployment</B></P>

<UL>
	<LI>Triceps will be used to author and administer each of these instruments
	<LI>Each subject will be emailed an invitation to participate
	<UL>
		<LI>there will be a brief description of the goals of study (if appropriate), the estimated time-commitment required,
		and the person to contact in case of questions or concerns
		<LI>a message such as (but probably shorter than)
		<UL>
			<P><BR>
			Hi, I am a graduate of Cornell Med School doing a clinical and informatics research fellow at CPMC and PI. I am
			conducting a study to assess which of several computerized versions of the GAF and BPRS are most sensitive, reliable,
			and efficient in the clinical environment. Your department has identified you as a [psychiatric/non-psychiatric]
			[medical student/resident/attending/nurse/sw] at [NYH/CPMC/PI]. As such, you are invited to participate in this
			email-based study, which should take less than 5 minutes of your time.<BR>
			<BR>
			The study is composed of 26 one-paragraph case vignettes of fictitious patients. You will be asked to determine
			the GAF and BPRS scores for each &quot;patient&quot;. It should take you from 1-5 minutes to read and assess each
			case, depending upon your level of experience.<BR>
			<BR>
			You are not required to complete all 26 cases.<BR>
			<BR>
			However, these vignettes are educationally useful. After you have scored each case, you will be shown the GAF and
			BPRS scores the experts agree is most correct, and provided with a detailed description of the reasons behind their
			decisions.<BR>
			<BR>
			Thus, you may want to complete several or all of the cases, at your leisure.<BR>
			<BR>
			You can return to complete, or re-do each case as many times as you like.<BR>
			<BR>
			Your privacy is paramount. You may notice that the link to the study's home page contains an unique alphanumeric
			key. Although your email addresses were collected from the departmental lists, neither I nor the automated analysis
			system keeps track of your name (or email address) after the access key has been sent to you. The key only contains
			references to you profession, level of training, and institution. [So trainees, you don't have to worry about your
			supervisor getting hold of your individual results].<BR>
			<BR>
			Thank you for your participation. If you have any questions or comments, please don't hesitate to contact me at
			<A HREF="mailto:thomas.white@dmi.columbia.edu">thomas.white@dmi.columbia.edu</A><BR>
			<BR>
			----- Thomas M. White, MD, MS; Clinical Research Fellow, Department of Medical Informatics, CPMC/NYSPI ----
		</UL>
		<LI>a link will point them to the entry page for the study. Embedded within it will be a key with which to uniquely
		but anonymously identify them to the system
	</UL>
	<LI>Entry page
	<UL>
		<LI>instructions &amp; time-to-complete
		<LI>who to contact in case of questions or concerns
		<LI>a button to decline to participate
		<LI>buttons to start each of the 26 studies (one per vignette)
	</UL>
	<LI>The System (Triceps) will, for each case:
	<UL>
		<LI>authenticate each subject, ensuring that non-authorized individuals are not able to contaminate the study data
		<LI>record the subjectID, profession, training level, and institution for each subject
		<LI>record copious timing information for each case
		<UL>
			<LI>date/time that subject first sees the case vignette
			<LI>date/time that subjects starts the assessment of case
			<LI>every event (key press, mouse click, help-request, submit) at every stage within the assessment - to millisecond
			accuracy
		</UL>
		<LI>calculate and store the GAF and BPRS scores based upon the subject's inputs
		<LI>upon completion of a case, report back to the subject the expert consensus as to what the GAF and BPRS score
		should be, and an explanation as to why
		<LI>email a message to the subject thanking them for participating in the study, and inviting them to fill out
		a 15 question survey evaluating the Triceps system itself (independent of the GAF and BPRS content).
	</UL>
</UL>

<P ALIGN="CENTER"><B>Analysis</B></P>

<UL>
	<LI>As indicated above in the <I>Questions</I> section.
	<LI>Alternatively, if it is possible to collect a sufficient N:
	<UL>
		<LI>MANCOVA of accuracy vs. time-to-complete of GAF and BPRS (total scores &amp; subscales) with computerized-version#,
		profession, educational level, institute(?), case#, sequence# [the order in which the subject completed the vignette],
		and date/time(?) as independent variables.
		<LI>Reliability of GAF/BPRS sub-components / sub-scales (e.g. which sub-components contribute the most variance
		to the GAF/BPRS scores).
	</UL>
	<LI>Triceps satisfaction survey.
	<LI>Assessment of respondents vs. non-respondents.
</UL>

<P ALIGN="CENTER"><B>Required Resources</B>

<UL>
	<LI>A clinical research advisor who will:
	<UL>
		<LI>help facilitate the establishment and maintenance of liaisons with the medical schools
		<LI>provide critical review of the design and analysis of this study
		<LI>suggest potential ways to enhance or extend this study
		<LI>suggest best granting agencies and journals to target with the results of this study
		<LI>help guide me through the grant application and publication processes
		<LI>provide critical review of manuscripts
		<LI>suggest appropriate conferences at which preliminary results should be presented.
	</UL>
	<LI>Liaisons to NYH and CPMC medical schools for permission (and hopefully blessing) to conduct this study, as
	well as to access the necessary email lists.
	<LI>Permission to use the GAF vignettes.
	<LI>IRB permission to collect numerical assessment of fictitious &quot;patients&quot; from anonymized health care
	workers?
	<LI>Access to or collaboration with a statistician who will:
	<UL>
		<LI>help guide me through the planning and implementation of this study (e.g. power analyses, fall-back options
		if # respondants are too small, etc.)
		<LI>suggest improvements and/or extensions to the design and analysis of this data
	</UL>
	<LI>Access to appropriate statistical analysis and graphical reporting software.
	<LI>Access to secure, frequently backed-up storage space for the &quot;database&quot; of subjects and their results.
	<LI>Technical
	<UL>
		<LI>author and get assessments of the Triceps implementations of the GAF, GAF-Tree, e-GAF, BPRS-paragraph, and
		e-BPRS [done]
		<LI>author intro-page for the study [done]
		<LI>minor revisions to Triceps to support subject authentication, and transfer of completed data to secure storage
		space
	</UL>
</UL>

<P ALIGN="CENTER"><B>Funding</B></P>

<UL>
	<LI>No additional funding necessary. My salaary as a clinical fellow would cover all necessary expenses.
</UL>

<P ALIGN="CENTER"><B>Time-Line</B></P>

<UL>
	<LI>When can data collection begin?
	<UL>
		<LI>As soon as the administrative and political issues are resolved.
		<UL>
			<LI>Selection of an Advisor
			<LI>IRB approval
		</UL>
		<LI>N.B. All technical issues have already been resolved. <I>Triceps</I> and the questionnaires are ready for deployment.
	</UL>
	<LI>How long will data collection last?
	<UL>
		<LI>Approximately one week.
		<UL>
			<LI>Initial email soliciatation for involvement
			<LI>Follow-up email to non-respondants
			<LI>Possible follow-up telephone calls
		</UL>
	</UL>
	<LI>How long will it take to analyze the data?
	<UL>
		<LI>This depends upon the sample size and response rate.
		<LI>Initial, summary statistics would be available within a day of completion of data collection
		<LI>More detailed analyses will require collaboration with a statistician, and might require several weeks or months
		to complete
	</UL>
</UL>

<P ALIGN="CENTER"><B>Potential Publications</B> (of this and follow-up studies)

<UL>
	<LI>JAMIA
	<UL>
		<LI>Triceps - A Rapid Application Development and Deployment Environment for Providing and Collecting Structured
		Information via the Web
		<LI>Triceps - A Pragmatic Merger and Implementation of the W3C XML-Schema, XForms, and XHTML Proposals
	</UL>
	<LI>JAMA / NEJM
	<UL>
		<LI>Bringing Psychology to Clinical Care - Challenges, Solutions, and Opportunities
		<LI>Web-Based Patient Assessment - At Home, and in the Waiting Room
	</UL>
	<LI>Psychiatry
	<UL>
		<LI>Re-Assessing the GAF and BPRS - The Need for Standardized, Easy to Use Data Collection Tools
		<LI>A Framework for Computerized Patient Records in Psychiatry - Needs Analysis and Potential Solutions.
	</UL>
	<LI>Psychology
	<UL>
		<LI>Triceps - A Novel, Web-Based Tool for Building Structured Interviews and Questionnaires
		<LI>Triceps - A Tool for Efficiently Assessing the Reliability and Validity of Modifications of Established Instruments
	</UL>
	<LI>Public Health
	<UL>
		<LI>Triceps - A Tool for Efficaciously Implementing International Public Studies [Boricua Youth Study as an Example]
	</UL>
</UL>

<P ALIGN="CENTER"><B>References</B></P>

<OL>
	<LI><A NAME="1"></A>Endicott J, Spitzer RL, Fleiss JL, et al: The Global Assessment Scale: a procedure for measuring
	overall severity of psychiatric disturbance. Arch Gen Psychiatry 33:766–771,1976<B>.</B>
	<LI><A NAME="2"></A>Overall JE, Gorham DR. The Brief Psychiatric Rating Scale. Psychol Rep 1962;10:799-812.
	<LI><A NAME="3"></A>Laska EM, Klein DF, Lavori PW et al. Design issues for the clinical evaluation of psychotropic
	drugs. In: Prien RF, Robinson DS, eds. Clinical Evaluation of Psychotropic Drugs: Principles and Guidelines. New
	York: Raven Press, 1994;29-67.
	<LI><A NAME="4"></A>Harvey PD, Davidson M, White L, et al. Empirical evaluation of the factorial structure of clinical
	symptoms in schizophrenia: effects of typical neuroleptics on the Brief Psychiatric Rating Scale. Biological Psychiatry
	1996;40:755-760.
	<LI><A NAME="5"></A>Mueser KT, Curran PJ, McHugo GJ. The factor structure of the Brief Psychiatric Rating Scale
	in schizophrenia. Psychological Assessment 1997, in press.
	<LI><A NAME="6"></A>Guy W, Cleary P, Bonato RR. Methodological implications of a large central data system. Proceedings
	IXth Congress CINP. Amsterdam: Excerpta Medica, 1975.
	<LI><A NAME="7"></A>Overall JE. The Brief Psychiatric Rating Scale in psychopharmacologic research. Mod Probl Pharmacopsychiatry
	1974;7:67-78.
	<LI><A NAME="8"></A>***GAF-Tree reference***
	<LI><A NAME="9"></A>Schneiderman B. Designing the User Interface: Strategies for effective human computer interaction,
	3rd Ed.. Massachusetts: Addison-Wesley, 1998; 135-144.
</OL>


</BODY>

</HTML>